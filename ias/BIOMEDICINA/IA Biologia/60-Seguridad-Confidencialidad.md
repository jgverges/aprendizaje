## 🔒 Seguridad y confidencialidad de datos sensibles

### ⚠️ Consideración crítica: protección de datos de investigación

Al usar herramientas de IA en investigación biomédica, especialmente con datos de salud sensibles como VIH, es **fundamental** entender cómo se manejan tus datos y proteger la confidencialidad de tu investigación.

### ¿Qué pasa con tus datos cuando usas herramientas de IA?

#### Cómo funcionan las herramientas de IA con tus datos

**Herramientas basadas en la nube (ChatGPT, Claude online, Elicit, etc.):**

- **Tus datos se envían a servidores externos** para procesamiento
- **Pueden ser almacenados temporalmente** para mejorar el servicio
- **Pueden ser usados para entrenar modelos** (según políticas de cada herramienta)
- **Existe riesgo de acceso no autorizado** (aunque las empresas tienen medidas de seguridad)

**Herramientas locales o con opciones de privacidad (Cursor, DeepL, algunas versiones):**

- **Procesamiento puede hacerse localmente** (depende de configuración)
- **Menor riesgo de fuga**, pero no cero riesgo
- **Requiere configuración específica** para máxima privacidad

---

### 🚨 Datos que NUNCA debes subir a herramientas de IA

#### Categorías de datos sensibles a proteger

| Tipo de dato | Ejemplos | Riesgo si se filtra | ¿Usar IA? |
|--------------|----------|---------------------|-----------|
| **Datos de pacientes identificables** | Nombres, DNI, direcciones, historial clínico completo | Violación GDPR/HIPAA, pérdida de privacidad | ❌ NUNCA |
| **Resultados no publicados críticos** | Datos experimentales exclusivos, descubrimientos patentables | Pérdida de ventaja competitiva, riesgo de plagio | ⚠️ Solo versiones locales/privadas |
| **Información de protocolos patentados** | Métodos exclusivos, procesos propietarios | Pérdida de propiedad intelectual | ⚠️ Solo versiones locales/privadas |
| **Información confidencial de colaboraciones** | Datos compartidos bajo acuerdos de confidencialidad | Violación de acuerdos legales | ❌ NUNCA |
| **Datos de ensayos clínicos en curso** | Resultados preliminares no publicados | Riesgo regulatorio, pérdida de integridad del estudio | ❌ NUNCA |
| **Códigos de identificación de muestras** | Links entre códigos y pacientes | Re-identificación de pacientes | ❌ NUNCA |

---

### 🔐 Mejores prácticas de seguridad para investigación biomédica

#### 1. Anonimización y desidentificación antes de usar IA

**Antes de subir datos a cualquier herramienta de IA:**

✅ **SÍ puedes hacer:**
- Usar datos ya publicados (papers públicos)
- Usar datos completamente anonimizados (sin posibilidad de re-identificación)
- Usar datos agregados (promedios, estadísticas, sin datos individuales)
- Usar ejemplos hipotéticos o sintéticos

❌ **NO debes hacer:**
- Subir datos con identificadores de pacientes
- Subir datos que permitan re-identificación
- Subir resultados experimentales exclusivos no publicados
- Subir información que comprometa la confidencialidad

**Ejemplo de anonimización segura:**

**❌ INCORRECTO (datos sensibles):**
```
Paciente: María González, DNI 12345678X
Muestra: VIH-001-2024
Resultado: Carga viral 10.000 copias/mL, células CD4+ 350/μL
```

**✅ CORRECTO (datos anonimizados):**
```
Grupo de estudio: Cohort A
Muestra: Anonimizada, código interno
Resultado agregado: Carga viral promedio 8.500-12.000 copias/mL,
CD4+ promedio 300-400/μL (rango del estudio)
```

---

#### 2. Elegir herramientas con políticas de privacidad adecuadas

**Antes de usar cualquier herramienta, verifica:**

| Aspecto crítico | Qué buscar | Ejemplos de herramientas |
|----------------|------------|-------------------------|
| **Política de no entrenamiento** | Que tus datos NO se usen para entrenar modelos | Cursor (opciones locales), algunas versiones empresariales |
| **Encriptación end-to-end** | Datos encriptados en tránsito y reposo | Herramientas empresariales, versiones privadas |
| **Cumplimiento GDPR/HIPAA** | Cumplimiento con regulaciones de protección de datos | Zotero (local), versiones empresariales |
| **Opciones locales/on-premise** | Procesamiento en tus propios servidores | Algunas versiones empresariales |
| **Política de retención de datos** | Cuánto tiempo guardan tus datos | Revisar términos de cada herramienta |

---

#### 3. Estrategias seguras por tipo de herramienta

**Para herramientas de redacción y estructuración (Cursor, ChatGPT):**

✅ **Usar de forma segura:**
- Solo texto ya publicado o completamente anonimizado
- Estructurar papers usando información general (no datos específicos)
- Redactar usando literatura ya publicada
- NO incluir datos experimentales exclusivos

**Ejemplo seguro:**
- ✅ "Redacta una introducción sobre senescencia celular en VIH basándote en literatura publicada"
- ❌ "Analiza estos resultados experimentales exclusivos sobre nuestros pacientes: [datos reales]"

---

**Para herramientas de extracción de datos (Elicit):**

✅ **Usar de forma segura:**
- Solo papers ya publicados (PDFs públicos)
- NO subir resultados experimentales propios no publicados
- NO subir datos de pacientes identificables
- Verificar política de privacidad de Elicit (puede procesar PDFs)

**Consideración importante:** Elicit procesa PDFs que subes. Asegúrate de que solo contengan información pública.

---

**Para herramientas de gestión de referencias (Zotero):**

✅ **Relativamente seguro:**
- Funciona principalmente con metadatos (títulos, autores, años)
- Puede funcionar localmente (menor riesgo)
- NO incluye datos experimentales en referencias
- Revisa configuración de sincronización en la nube

---

**Para herramientas de traducción (DeepL):**

⚠️ **Usar con precaución:**
- DeepL puede almacenar texto traducido temporalmente
- NO traducir datos de pacientes identificables
- NO traducir resultados exclusivos no publicados
- Usar versión empresarial si trabajas con datos sensibles frecuentemente

---

#### 4. Configuración de privacidad recomendada

**Para Cursor (si trabajas con datos sensibles):**

1. **Revisa configuración de privacidad:**
   - Ve a Settings → Privacy
   - Desactiva "Share usage data" si está disponible
   - Usa modelos locales cuando sea posible

2. **No uses funciones que envíen código automáticamente:**
   - Desactiva auto-completado en archivos con datos sensibles
   - Usa modo "Ask" en lugar de "Agent" para consultas sobre datos sensibles

3. **Considera versión empresarial:**
   - Si trabajas frecuentemente con datos sensibles, considera versión con mayor privacidad

---

### 🛡️ Riesgos de fugas y cómo prevenirlos

#### Principales riesgos de seguridad

| Riesgo | Causa | Impacto | Prevención |
|--------|-------|---------|------------|
| **Fuga de datos de pacientes** | Subir datos identificables a herramientas en la nube | Violación legal, pérdida de privacidad, sanciones | Anonimización estricta, NO subir datos identificables |
| **Fuga de resultados exclusivos** | Subir datos experimentales no publicados | Pérdida de ventaja competitiva, riesgo de plagio | Solo usar con datos ya publicados o versiones locales |
| **Re-identificación** | Datos aparentemente anonimizados pero con información suficiente | Identificación de pacientes o muestras | Eliminar todos los identificadores posibles |
| **Acceso no autorizado** | Brechas de seguridad en servicios en la nube | Exposición de datos confidenciales | Elegir herramientas con buen historial de seguridad |
| **Uso de datos para entrenamiento** | Políticas que permiten usar datos para mejorar modelos | Tus datos pueden aparecer en respuestas a otros usuarios | Elegir herramientas con política de no-entrenamiento |

---

### ✅ Guía práctica: flujo de trabajo seguro

#### Para redactar papers con datos sensibles

**Flujo SEGURO:**

1. **Preparar datos anonimizados:**
   - Eliminar todos los identificadores
   - Usar datos agregados en lugar de individuales
   - Crear versiones hipotéticas para ejemplos

2. **Usar IA solo para estructuración general:**
   - Cursor para estructura de paper (sin datos específicos)
   - Literatura ya publicada para contexto
   - NO incluir resultados experimentales exclusivos

3. **Insertar datos reales manualmente:**
   - Después de usar IA para estructuración
   - Insertar datos reales directamente tú
   - Verificar que no queden datos sensibles en historial de IA

4. **Limpiar historial:**
   - Borrar conversaciones que contengan información sensible
   - Cerrar sesiones después de trabajar con datos confidenciales

---

#### Para análisis de literatura (más seguro)

**Elicit y Research Rabbit son relativamente seguros porque:**

- Trabajan principalmente con papers ya publicados
- No requieren subir tus datos experimentales
- Puedes hacer búsquedas sin exponer datos propios

**Precauciones adicionales:**
- NO subas PDFs con datos experimentales propios
- Solo usa papers públicos
- Verifica que los papers que analices sean realmente públicos

---

### 📋 Checklist de seguridad antes de usar cualquier herramienta

Antes de subir cualquier dato a una herramienta de IA, verifica:

- [ ] ¿Los datos contienen información identificable de pacientes? → **NO usar IA**
- [ ] ¿Los datos son resultados experimentales exclusivos no publicados? → **Solo versiones locales/privadas**
- [ ] ¿Los datos están completamente anonimizados? → ✅ Puedes considerar IA
- [ ] ¿He revisado la política de privacidad de la herramienta? → **Hazlo siempre**
- [ ] ¿La herramienta cumple con GDPR/HIPAA si es necesario? → **Verifica para datos de salud**
- [ ] ¿He desactivado funciones de entrenamiento/mejora? → **Si es posible**
- [ ] ¿Puedo usar una versión local/privada? → **Ideal para datos sensibles**
- [ ] ¿He eliminado todos los identificadores posibles? → **Verifica múltiples veces**

---

### 🎯 Recomendación final: principio de precaución

**Regla fundamental:**

> **Si tienes dudas sobre si un dato es sensible, trata como si fuera sensible.**

**Para investigación biomédica con datos de salud:**

1. **NUNCA subas datos de pacientes identificables** a ninguna herramienta de IA
2. **Usa IA solo para tareas generales** (estructuración, redacción de literatura ya publicada)
3. **Mantén datos experimentales exclusivos fuera de IA** hasta que estén publicados
4. **Verifica políticas de privacidad** de cada herramienta antes de usar
5. **Considera versiones empresariales/privadas** si trabajas frecuentemente con datos sensibles
6. **Cuando sea posible, usa procesamiento local** en lugar de herramientas en la nube

**La seguridad de los datos de investigación y la privacidad de los pacientes siempre debe ser la prioridad sobre la comodidad de usar IA.**

---


---

← [Anterior](55-Limites-Precauciones.md) | [↑ Índice](00-INDEX.md) | [Siguiente](70-Plan-Accion.md) →